

两方面工作：cartographer代码解读与拆解    ros（机器人操作系统）文件调配+相关功能包调用+参数调试

1、cartographer代码解读与拆解
	了解cartographer原理，源码解读，拆解出cartographer源码中定位部分，用于初始定位

2、ros系统文件调配，导航功能配置
	学习了解ros系统工作原理，配置imu、lidar、kinect、超声波数据输出与衔接
	学习ros中move_base功能包，配置、调整导航文件与参数


形成的机器人定位与导航方案：

1、建图（grid map）：利用cartographer+lidar/kinect（2d）数据进行建图，并保存建图过程生成的submap信息以及生成的map

2、初始定位：从cartographer源码中剥离出每一帧数据的定位方法，利用上述步骤保存下的submap信息进行定位，得出机器人相对于map的初始位置

3、路径规划与导航：步骤2得出机器人相对于map的初始位置，调出可视化界面，由scan数据可以生成周围障碍物信息。设置目的位置后，ros中开源包可计算最优路径，同时有避障功能

4、同时定位与建图：步骤3路径规划完成，机器人开始运动，运行cartographer，同时定位与建图，可以得到机器人相对于初始位置的关系，初始位置与map的位置关系已得出，从而可知机器人在地图中的位置


目前已完成工作：

1、lidar建图+定位+导航（2维）

2、kinect2维建图+定位+导航

3、kinect2维建图+定位+3维导航（很吃计算资源，pc运行稳定，tx1运行效果不理想）

4、tof建图（tof为杭州公司产品，建图效果极差，有待调试）


后续工作：

1、imu数据调试（赵老师说imu数据对于cartographer非常重要，可以有效减少搜索空间，对于计算能力有限的硬件可以有效提高效果）

2、评估tof质量（已录制视频，可看kinect与tof点云效果，tof不如kinect，相差挺大的）

3、tof建图、定位、导航优化（调参+更改建图分辨率）

4、评估cartographer在slam中定位精度，以及将机器人运动过程中生成的map发送到ros作为local_map参与局部规划是否可行（如此可以减少计算量）

5、尝试在slam时直接加载之前的submaps，不断回环（意味着不是从0开始slam）

6、测试不同处理器性能，选用适用的处理器

7、后续可能增加人脸识别等深度网络，需考虑以下问题：
	1、处理器，处理平台选择问题
	2、人脸检测步骤如何完成（无网络）
	3、网络的训练与部署


目前机器人方案存在的问题：

1、整个导航行走的方案非常依赖于初始定位结果，如若初始定位出错，后续无法进行（是否可以走一段时间再重新定位）

2、初始定位后，行走时的SLAM依然可能出错，寻找闭环、优化计算非常依赖处理器性能，在一定程度上，处理器性能越高，SLAM效果越好






